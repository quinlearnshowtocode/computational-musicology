---
title: "Themed dashboard"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme:
      bg: "#121212"  
      fg: "#E0E0E0"   
      primary: "#BB86FC"
      base_font:
        google: Prompt
      code_font:
        google: JetBrains Mono
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
# Install thematic and un-comment for themed static plots (i.e., ggplot2)
# thematic::thematic_rmd()
```

```{r}
library(tidyverse)
library(tidymodels)
library(plotly)
library(heatmaply)
library(protoclust)
library(cowplot)
library(spotifyr)
library(compmus)
library(ggdendro)
```

```{r}
library(patchwork)
```
### Hierachical clustering for cloud rap playlist Classifier 1 


```{r, results = 'hide'}
library(tidyverse)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(spotifyr)
library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  
```



```{r}
library(tidyverse)
```

```{r}
library(tidymodels)
```


```{r}
cloud<-get_playlist_audio_features("", "1sIcT9bfCD4C53ZjKXWy7M")
```

```{r}
cloud <-
  head(cloud,20) |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))
```



```{r}
cloud_juice1 <-
  recipe(
    track.name ~  #~ for prediction models, on left is the thing you are predicting, right side is the predictors) take out/add the things you wish, and rationalize your choice
      danceability + # these are all the features
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` + #these are all the pitch classes
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 + #these are all the timbre features
      c07 + c08 + c09 + c10 + c11 + c12,
    data = cloud
  ) |>
  step_center(all_predictors()) |> #you can also change here, center and scale, and range, which move everything to one scale.
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(cloud |> mutate(track.name = str_trunc(track.name, 20))) |> #cut the track names to only 20 characters
  juice() |> 
  column_to_rownames("track.name")
```


```{r}
cloud_dist1 <- dist(cloud_juice1, method = "euclidean") #the distance
```

```{r}
cloud_dist1 |> 
  hclust(method = "single") |> # Try single, average, and complete. The linkage
  dendro_data() |>
  ggdendrogram() 
```

***As we can see, "Rest" and "Timebomb" are the most similar songs in this classifier. Upon listening, I noticed that these songs both share the elements as trap, and similar vocal voices and beat patterns. 





### chordogram of "straight to the moon!" Aesthetic rap

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )



key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

```


```{r}
moon <-
  get_tidy_audio_analysis("5eBpfwTJBusVJp8VcLwokY") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
get_tidy_audio_analysis("5eBpfwTJBusVJp8VcLwokY") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) |> 
  compmus_match_pitch_template(chord_templates, "euclidean", "manhattan") |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***

[link to the song](https://open.spotify.com/track/5eBpfwTJBusVJp8VcLwokY?si=e290b9ebe2b04523)
The chordogram of this aesthetic rap song shows a pattern of the chords switching among A7, E7, B7 and D7, however, when exactly the chord changes is not very clear from this graph. The level of measurement is based on each bar.There is no clear signs for modulations here, which makes sense because it is a rap song with simple musical structures.


### Keygram of "straight to the moon!" Aesthetic rap


```{r}
moon |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### Self similarity matrix "crossy roads"
```{r}
road <-
  get_tidy_audio_analysis("3UOz51ElOJLPyRxuHbFOEW") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```


```{r}


timbreroad<- road |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "chroma")


chromaroad<- road |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "timbre")

# Combine the two plots side by side
combined_plot <- timbreroad+ chromaroad
# Display the combined plot
combined_plot
```

***

This aesthetic rap song has a very simple structure, basically it's a loop of melody playing in the background every 10 seconds-ish and the rapper raps without much pith changes, which is reflected in the self similarity matrxix of chroma and timbre here. The green part in both matrices reflect that there is a part around 20-50 seconds that is unique to other sections, which is in fact a change in the loop pattern,then it came back.

[here is the song](https://open.spotify.com/track/3UOz51ElOJLPyRxuHbFOEW?si=963f41f0a4ce404c)

### Aesthetic vs Cloud rap

corpus discription The corpus I've chosen to explore a unique collection of music from Spotify, particularly focusing on playlists curated by the account "The Sound of Spotify." These playlists are distinguished by their meticulous categorization into highly specific and nuanced genres, made possible through Spotify's algorithms and computational analysis of musical elements. This meticulous approach to classification allows for an in-depth exploration of niche musical styles, making it a rich area for study and comparisons.

Thus, the playlist I would like to analyse by the sound of spotify is The Sound of Aesthetic RapLinks to an external site., which is a more niche and regional genre that is close to aesthetic rap according to "the sound of spotify". aesthetic rap is a new term and genre which is described as "a subgenre of rap music that emphasizes a particular style, mood, or "aesthetic" quality in its production, lyrics, and overall presentation." But by listen through it, some of them have classical music influences and some are lo-fi vibes. The evidences show that the elements that are considered as "aesthetic is very nuanced and it would be fruitful for further investigation to see how can spotify detect the "aesthetics". In comparison, I would like to analyse the playlist of The sound of cloud raps. Cloud rap is another subgenre of rap, which has similar characteristics with aesthetic raps on its impression, some of the songs from both genre both feature ethereal, dreamy and lo-fi beats. The corpus will try to find out what spotify algorithms think about the difference between these genres.

### Speechiness and Valence

```{r}
cloud<-get_playlist_audio_features("", "1sIcT9bfCD4C53ZjKXWy7M")
cloud<-head(cloud,20)
aes<-get_playlist_audio_features("", "2OY7wFfc4FIedjHBF95f9t")
aes<-head(aes,20)
```

```{r}

rap <-
  bind_rows(
     cloud |> mutate(category = "Cloud Rap"),
     aes|> mutate(category = "Aesthetic Rap")
  ) 

rap|>
  ggplot(aes(x= track.name, y = speechiness, color=category,size=valence )) +
  geom_point()+
  coord_flip()+labs(title = "Speechiness and Valence in Aesthetic and Cloud rap")


#put the color to category. 



```


***
In this visualization we can see that aesthetic rap songs(red) in the corpus are more speechy than cloud rap(blue), with no obvious difference in valence.

### Cepstrogram for "Crossy Roads" Aesthetic rap

```{r}
road <-
  get_tidy_audio_analysis("3UOz51ElOJLPyRxuHbFOEW") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

```

```{r}
road |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

***

The graph shows alternation of sections.

From the cepstrogram we can see that this song has 3 parts and from 0-15 to 50-100 could be similar sections in terms of timbre.

[here is the song](https://open.spotify.com/track/3UOz51ElOJLPyRxuHbFOEW?si=963f41f0a4ce404c)



Extend your storyboard from last week to include an analysis of rhythm or tempo. For example:

Make a histogram of tempi for different groups in your corpus.
Make tempograms for outliers or archetypes in your corpus.
Compare the tempo curves to the self-similarity matrices of multiple performances of the same piece (easiest for classical music).
Submit the URL to your new web page for review.