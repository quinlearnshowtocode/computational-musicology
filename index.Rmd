---
title: "French, German, Korean, Spanish Hip-hop"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    theme:
      bg: "#121212"  
      fg: "#E0E0E0"   
      primary: "#BB86FC"
      base_font:
        google: Prompt
      code_font:
        google: JetBrains Mono
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
# Install thematic and un-comment for themed static plots (i.e., ggplot2)
# thematic::thematic_rmd()
```

```{r}
library(tidyverse)
library(tidymodels)
library(plotly)
library(heatmaply)
library(protoclust)
library(cowplot)
library(spotifyr)
library(compmus)
library(ggdendro)
```

```{r}
library(patchwork)
library(tidyr)
library(ggplot2)
```

### A transcultural,computational musiclogy comparitive study on Hip-pop music

The corpus of choice are the current popular tracks across 4 different cultures where a relatively larger audience base and hippop culture is active, these are french, german, spanish(latin american), and korean hip-pop

Spanish(Latin american) Hip-hop: <iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4cy45EPpNjdniwLvfLDt0K?utm_source=generator&theme=0" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

German Hip-hop: <iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/5k0hLNPNjD7iYs1PMtHEyM?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Korean Hip-hop: <iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6eCZ6NrzVYcPB1WjlMeDV9?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

French Hip-hop: <iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/0FiYE4GULpT2A2G682GdWd?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### A transcultural,computational musiclogy comparitive study on Hip-pop music, research question and Assumptions

How do the audio features of the most popular hip-hop tracks vary across different linguistic and cultural contexts in the current year?

This question invites an analysis of how musical trends and listener preferences might differ by culture, as reflected in the music's audio features (e.g., danceability, energy, valence).

What can the popularity and audio features of hip-hop tracks across languages tell us about the global influence of certain musical characteristics?

This question focuses on identifying which musical features are universally appealing or culturally specific in the context of hip-hop. How does the lyrical content (as inferred from speechiness, instrumentalness, )

### Trends in the Hip-pop music in different languages/cultures

```{r}
es <- readRDS(file = "data/es.RDS")
```


```{r}
fr <- readRDS(file = "data/fr.RDS")
```

```{r}
kr <- readRDS(file = "data/kr.RDS")
de <- readRDS(file = "data/de.RDS")

```


```{r}
playlist_files <- list(
  fr = 'data/fr.rds',
  de = 'data/de.rds',
  es = 'data/es.rds',
  kr = 'data/kr.rds'
)


# Step 2: Function to load features from local RDS files
load_playlist_features <- function(file_path) {
  features <- readRDS(file_path)
  return(features)
}

# Step 3: Load all playlists' features
playlist_features <- lapply(playlist_files, load_playlist_features)
```

```{r}
#average features 
average_features <- sapply(playlist_features, function(features) {
  data.frame(
    danceability = mean(features$danceability, na.rm = TRUE),
    energy = mean(features$energy, na.rm = TRUE),
    valence = mean(features$valence, na.rm = TRUE),
    speechiness = mean(features$speechiness, na.rm = TRUE),
    instrumentalness = mean(features$instrumentalness, na.rm = TRUE),
    tempo = mean(features$tempo, na.rm = TRUE),
    acousticness = mean(features$acousticness, na.rm = TRUE),
    liveness = mean (features$liveness, na.rm=TRUE),
    loudness = mean (features$loudness, na.rm= TRUE)
  )
}, simplify = FALSE)


average_features_df <- do.call(rbind, average_features)
row.names(average_features_df) <- names(average_features)
average_features_df$Playlist <- row.names(average_features_df)

```
#### Bar plots
```{r}
# Reshape the data 
average_features_long <- pivot_longer(average_features_df, 
                                      cols = c(danceability, energy, valence, speechiness, instrumentalness,liveness,loudness, acousticness,tempo), 
                                      names_to = "Feature", 
                                      values_to = "Average")

bar<-ggplot(average_features_long, aes(x = Playlist, y = Average, fill = Feature)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
  theme_minimal() +
  labs(title = "Average Spotify Audio Features Across Playlists", x = "De=German Es=Spanish Fr=French Kr=Korean", y = "Average Value") +
  scale_fill_brewer(palette = "Set3") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~Feature, scales = "free_y", ncol = 3)  


```

```{r}


all_features_df <- do.call(rbind, playlist_features)

# Reshape for plotting
all_features_long <- pivot_longer(all_features_df, 
                                  cols = c(danceability, energy, valence, speechiness, instrumentalness, liveness, acousticness), 
                                  names_to = "Feature", 
                                  values_to = "Value")


box<-ggplot(all_features_long, aes(x = Feature, y = Value, fill = playlist_name)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Boxplot of Spotify Audio Features by Playlist", x = "Feature", y = "Value") +
  scale_fill_brewer(palette = "Set3")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r plot1, fig.show='hold', out.width='100%', out.height='400px'}
p_combined <- bar + box

# To print the combined plot
p_combined
```

***

From the graph we can see that the average value of the audio features of the four hip-hop playlists shows the most variety in instrumentalness, acouscticness, valence, speechiness and loudness. Spanish hip-hop music has the highest speechiness, instrumentalness, acousticness and valence, While french music has the lowest instrumentalness, speechiness, and energy. German hip-hop music is the lowest in valence and instrumentalness, while Korean hip-hip music is the highest in energy and valence, but lowest in loudness and acousticness and speechiness.

This exploratory analysis provides great insight into the difference in the popular hip-hop music across these cultures, which could be a result of a variety of factors including historical music influences,linguistic characteristics, trends and the difference in the taste of the listeners(because in reversed that's also why they became so popular). This analysis gives us a good base for our further correlation, regression, single track analysis, and clustering.

### correlation

```{r}
all_features <- do.call(rbind, lapply(names(playlist_features), function(lang) {
  df <- playlist_features[[lang]]
  df$language <- lang
  return(df)
}))

numeric_columns <- c("danceability", "energy", "valence", "speechiness", "instrumentalness", "tempo","liveness","loudness","acousticness")
all_features[numeric_columns] <- lapply(all_features[numeric_columns], as.numeric)

```

```{r}
correlation_matrix <- cor(all_features[, numeric_columns], use = "complete.obs")


library(ggplot2)
library(reshape2) 

correlation_matrix_melted <- melt(correlation_matrix)
ggplot(correlation_matrix_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "", y = "", title = "Correlation Matrix of Audio Features", fill = "Correlation")
```


***
Loudness and energy have the strongest correlation, and

### chroma

```{r}

get_pitch_data <- function(features) {
  pitch_data <- features %>%
    select( key, mode) %>%
    mutate(
      major = as.numeric(mode == 1),
      minor = as.numeric(mode == 0)
    ) %>%
    group_by(key) %>%
    summarise(
      Count = n(),
      MajorCount = sum(major),
      MinorCount = sum(minor),
    ) %>%
    arrange(key)
  return(pitch_data)
}

# Analyze pitch data for each playlist
pitch_analysis <- lapply(playlist_features, get_pitch_data)
```

```{r}

key_labels <- c('C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B')


pitch_df <- bind_rows(
  lapply(names(pitch_analysis), function(playlist_name) {
    df <- pitch_analysis[[playlist_name]]
    df$Playlist <- playlist_name  # this ensures that playlist names are correctly assigned
    df
  }),
  .id = 'Playlist_id'
)


ggplot(pitch_df, aes(x = as.factor(key), y = Count, fill = Playlist)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  scale_x_discrete(labels = key_labels) +  # Apply the pitch class names
  scale_fill_brewer(palette = 'Set3', labels = c('DE', 'FR', 'ES', 'KR')) +  # Ensure correct playlist labels
  labs(x = 'Musical Key', y = 'Count', fill = 'Playlist', title = 'Pitch Class Profile Comparison Across Playlists') +
  theme_minimal()

```

***

something to say here

### What is the most representative track of each playlist?

```{r}
average_features_by_playlist <- all_features %>%
  group_by(language) %>%
  summarise(across(c(danceability, energy, valence, speechiness, acousticness, instrumentalness, liveness, tempo), mean, na.rm = TRUE))

```

```{r}
library(dplyr)

# Calculate average features by language
average_features_by_language <- all_features %>%
  group_by(language) %>%
  summarise(across(c(danceability, energy, valence, speechiness, acousticness, instrumentalness, liveness, tempo), mean, na.rm = TRUE))

# Define distance calculation function
calc_distance <- function(track_features, avg_features) {
  sqrt(sum((track_features - avg_features)^2))
}

# Initialize an empty list to store the most representative track for each language
representative_tracks <- list()

# Loop through each language to find the most representative track
for (lang in unique(all_features$language)) {
  tracks <- filter(all_features, language == lang)
  avg_features <- filter(average_features_by_language, language == lang)
  avg_features_numeric <- select(avg_features, -language)
  
  # Calculate distances from the average features for each track
  distances <- apply(select(tracks, c(danceability, energy, valence, speechiness, acousticness, instrumentalness, liveness, tempo)), 1, function(track_row) {
    calc_distance(track_row, unlist(avg_features_numeric))
  })
  
  # Find the track with the minimum distance
  min_distance_index <- which.min(distances)
  representative_track <- tracks[min_distance_index, ]
  
  # Store the most representative track in the list
  representative_tracks[[lang]] <- representative_track
}

# Print the most representative track for each language
for (lang in names(representative_tracks)) {
  representative_track <- representative_tracks[[lang]]
  track_name <- representative_track$`track.name`  # Adjust the column name based on your dataframe
  cat("The most representative track in", lang, "is:", track_name, "\n")
}

```

```{r}
library(plotly)

# Assuming 'all_features' already has the 'language' column and necessary audio features
pca_result <- prcomp(all_features[, c("danceability", "energy", "valence", "speechiness", "acousticness", "instrumentalness", "liveness", "tempo")], center = TRUE, scale. = TRUE)
pca_data <- as.data.frame(pca_result$x[, 1:2])
colnames(pca_data) <- c("PC1", "PC2")

# Add back the language and track names to the PCA data
pca_data$playlist_name <- all_features$playlist_name
pca_data$track_name <- all_features$track.name

```


```{r}
# Create a basic plotly object with PCA data
library(plotly)
library(dplyr)

# Assuming pca_data contains all tracks with PCA coordinates
# and representative_tracks contains the most representative tracks WITH their PCA coordinates

# Plot all tracks
p <- plot_ly(data = pca_data, x = ~PC1, y = ~PC2, type = 'scatter', mode = 'markers',
             text = ~paste("Track:", track_name, "<br>Playlist:", playlist_name),
             hoverinfo = "text", 
             marker = list(color = ~as.factor(playlist_name), size = 10, opacity = 0.6)) %>%
  layout(title = "PCA of Playlists",
         xaxis = list(title = 'Principal Component 1'),
         yaxis = list(title = 'Principal Component 2'),
         colorway = c("red", "blue", "green", "yellow"),
         hovermode = "closest")

# Ensure representative_tracks has PC1, PC2 for plotting
# This step might require adding PCA coordinates to representative_tracks, similar to pca_data

# Highlight the most representative tracks
for(lang in unique(representative_tracks$playlist_name)) {
  rep_track <- representative_tracks %>% filter(playlist_name == lang)
  p <- p %>% add_markers(data = rep_track, x = ~PC1, y = ~PC2,
                         marker = list(size = 15, symbol = 'star-diamond', line = list(color = 'black', width = 2)),
                         text = ~paste("Representative Track:", track_name, "<br>Playlist:", playlist_name),
                         hoverinfo = "text",
                         name = lang)  # This helps in differentiating groups
}

# Render the plot
p

```

***

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/7oIDr5FLnnjjwVyPQzd9fr?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

based on comparing the audio features of each track against the average audio features of all tracks within the same group. The track whose features are closest to these averages is considered the most representative. This process assumes that the "average sound" of a playlist can be quantified by the mean values of its tracks' audio features, such as danceability, energy, valence, etc.

The Steps Explained: Group and Average: For each group (identified by language in your dataset), calculate the average value for each audio feature across all tracks in that group. This gives a profile of what the average track looks like for each language in terms of its Spotify audio features.

Calculate Distance: For each track in a group, calculate the Euclidean distance between its audio features and the group's average audio features. The Euclidean distance is a measure of the overall difference between two sets of numbers, in this case, audio feature vectors. Mathematically, if you have two vectors x and y, the Euclidean distance d between them is calculated as d = sqrt(sum((x - y)\^2)), where you subtract corresponding elements of y from x, square the results, sum these squared differences, and take the square root of the sum.

Identify the Closest Track: The track with the smallest Euclidean distance to the average profile is considered the most representative of that group. It's the track whose features are, on average, closest to the mean features of the group, making it a sort of "central" track that best embodies the average characteristics of the group.

Extract Track ID: Once the most representative track is identified, its track_id (or any other relevant identifier) can be extracted for further use, like retrieving the track on Spotify or analyzing it further.



### Self-similarity matrices of most-representative tracks in each language

#### french

```{r}
cd <-
  read_rds('data/cd.rds') |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  cd |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  cd |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title="Fr-Christian Dior")
```

German

```{r}
thot <-
  read_rds('data/thot.rds') |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  thot |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  thot |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title="De-Thot")
```

Spanish

```{r}
como <-
  read_rds('data/como.rds') |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  como |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  como |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title="De-Thot")
```

Korean

```{r}
tl <-
  read_rds('data/tl.rds') |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  tl |> 
    compmus_self_similarity(pitches, "aitchison") |> 
    mutate(d = d / max(d), type = "Chroma"),
  tl |> 
    compmus_self_similarity(timbre, "euclidean") |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "", title="Kr- True love")
```

------------------------------------------------------------------------

some analysis

### Ceptrogram

### Random forest

```{r}
#hiphop <-
 # bind_rows(
  #  fr |> mutate(playlist = "French Hiphop"),
  #  de |> mutate(playlist = "German Hiphop"),
   # kr |> mutate(playlist = "Korean Hiphop"),
   # es |> mutate(playlist = "Latino Hiphop"),
 # ) |> 
 # add_audio_analysis()

fr_analyzed <- readRDS(file = "data/fr_all.RDS")
de_analyzed <- readRDS(file = "data/de_all.RDS")
kr_analyzed <- readRDS(file = "data/kr_all.RDS")
es_analyzed <- readRDS(file = "data/es_all.RDS")

hiphop <- bind_rows(fr_analyzed, de_analyzed, kr_analyzed, es_analyzed)

```



```{r}
hiphop_features <-read_rds('data/hiphop_features.rds')
```

```{r}
hiphop_recipe_all <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = hiphop_features           # Use the same name as the previous block.
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].
hiphop_cv <- hiphop_features |> vfold_cv(10)
```

```{r}
forest_model <-
  rand_forest() |>
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")
hiphop_forest <- 
  workflow() |> 
  add_recipe(hiphop_recipe_all) |> 
  add_model(forest_model) |> 
  fit_resamples(
    hiphop_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r}
get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  
```


```{r}
workflow() |> 
  add_recipe(hiphop_recipe_all) |> 
  add_model(forest_model) |> 
  fit(hiphop_features) |> 
  pluck("fit", "fit", "fit") |>
  ranger::importance() |> 
  enframe() |> 
  mutate(name = fct_reorder(name, value)) |> 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")
```

### KNN classification

```{r}
hiphop_recipe <-
  recipe(
    playlist ~ c01+c06+c12+tempo+acousticness+loudness+danceability+instrumentalness,
    data = hiphop_features
  ) |> 
  step_center(all_predictors()) |>
  step_scale(all_predictors())

```

```{r}
knn_model <-
  nearest_neighbor(neighbors = 1) |>
  set_mode("classification") |> 
  set_engine("kknn")
hiphop_knn <-
  workflow() |> 
  add_recipe(hiphop_recipe) |> 
  add_model(knn_model) |> 
  fit_resamples(hiphop_cv, control = control_resamples(save_pred = TRUE))
hiphop_knn |>
  collect_predictions() |> 
  conf_mat(truth = playlist, estimate = .pred_class) |> 
  autoplot(type = "heatmap")
```
   
### All precision and recall
Precision and Recall for Random Forest

```{r}
hiphop_forest |> get_pr()
```

Precision and Recall for KNN

```{r}
hiphop_knn|> get_pr()
```

***
Comparison


### K-means clustering for songs in all 4 playlsits: cluster numbers

```{r}
hiphop_juice <-
  recipe(
    track.name ~
      danceability + valence+ 
      loudness +
      speechiness +
      acousticness +
      instrumentalness + c01+c06+c12+tempo,
    data = hiphop_features
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(hiphop_features |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")
```


```{r}
library(cluster)     # for silhouette width
library(NbClust)

# Assuming 'data' is your dataset
nb <- NbClust(hiphop_juice, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans")

# Best number of clusters according to the majority rule
best_nc <- nb$Best.nc[1]

print(nb)

```


### K-means clustering for songs in all 4 playlsits

```{r}
pca_result <- prcomp(hiphop_juice, scale. = TRUE)
pca_scores <- as.data.frame(pca_result$x[, 1:2])
```

```{r}
set.seed(123)  # Ensure reproducibility
kmeans_result <- kmeans(hiphop_juice, centers = best_nc, nstart = 25)
```

```{r}
pca_scores$cluster <- as.factor(kmeans_result$cluster)
```

```{r}

# Combine PCA scores, clustering results, and names into one data frame
pca_scores <- data.frame(pca_result$x[, 1:2], cluster = kmeans_result$cluster)
pca_scores <- cbind(pca_scores, hiphop_features[, c("track.name", "playlist_name")])

# Create a ggplot
p <- ggplot(pca_scores, aes(x = PC1, y = PC2, color = factor(cluster), text = paste("Track:", track.name, "<br>Playlist:", playlist_name))) +
  geom_point() +
  theme_minimal() +
  labs(title = "K-means Clustering")

# Convert ggplot to a plotly interactive plot
p <- ggplotly(p, tooltip = "text") # 'text' specifies that the tooltip will show the 'text' aesthetic defined in ggplot
p

```


### A multi-lingual rap salad: Generating new playlists based on K-means clustering

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6rExGOsB7IsxtPdIHTjINn?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


### Conrtibutions and Limitations

Popularity as a Measure of Cultural Relevance: Assuming that the most popular tracks on Spotify accurately reflect cultural trends or preferences may overlook underground or emerging scenes not yet represented in mainstream charts.

Limitations of Spotify's Metrics: Spotify's definition of 'popularity' and its audio features are proprietary and algorithmically determined. While useful, they provide a specific lens on music that may not capture all dimensions of its cultural or artistic significance.
